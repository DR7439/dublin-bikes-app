{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0ab10900-db9c-48e8-bdf4-10d4e9d59343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from os import getenv\n",
    "from dotenv import load_dotenv\n",
    "from pmdarima import auto_arima\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "11a85cb8-144f-41bc-a545-16b9692a37e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(station_id):\n",
    "    # Load database connection parameters\n",
    "\n",
    "    PASSWORD = getenv(\"PASSWORD\")\n",
    "    \n",
    "    host_name = 'localhost'\n",
    "    username = 'root'\n",
    "    password = PASSWORD\n",
    "    database_name = \"dublinbikes\"\n",
    "\n",
    "    # Create the SQLAlchemy engine\n",
    "    engine = create_engine(f'mysql+pymysql://{username}:{password}@{host_name}/{database_name}')\n",
    "    \n",
    "    # SQL query\n",
    "    query = f\"\"\"\n",
    "    SELECT S.station_id, S.bike_stands, A.last_update, A.available_bikes, A.available_bike_stands,\n",
    "           W.temperature, W.humidity, W.weather_condition, W.wind_speed\n",
    "    FROM station S\n",
    "    JOIN availability A ON S.station_id = A.station_id\n",
    "    JOIN weather_data W ON A.station_id = W.station_id AND W.last_update = A.last_update\n",
    "    WHERE S.station_id = {station_id};\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the query and load the data into a DataFrame\n",
    "    df = pd.read_sql(query, engine)\n",
    "    print(df)\n",
    "    return df\n",
    "\n",
    "def clean_data(df):\n",
    "    # Convert 'last_update' from UNIX time in milliseconds to datetime and set as index\n",
    "    df['last_update'] = pd.to_datetime(df['last_update'], unit='ms')\n",
    "    df.set_index('last_update', inplace=True)\n",
    "\n",
    "    # Add day_of_the_week (0 = Monday, 6 = Sunday)\n",
    "    df['day_of_the_week'] = df.index.dayofweek\n",
    "    df['hour'] = df.index.hour\n",
    "    df['is_weekend'] = df['day_of_the_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "    \n",
    "    # Convert temperature from Kelvin to Celsius\n",
    "    df['temperature'] = df['temperature'] - 273.15\n",
    "    \n",
    "    # Aggregate numeric fields by mean and 'weather_condition' by mode\n",
    "    df_numeric = df.drop(columns=['weather_condition']).resample('30min').mean()\n",
    "    weather_condition_mode = df['weather_condition'].resample('30min').apply(lambda x: x.mode()[0] if not x.mode().empty else 'Unknown')\n",
    "    \n",
    "    # Combine the aggregated data\n",
    "    df_hourly = df_numeric\n",
    "    df_hourly['weather_condition'] = weather_condition_mode\n",
    "    \n",
    "    # Factorize the 'weather_condition' to turn it into a numeric variable\n",
    "    df_hourly['weather_condition_encoded'] = pd.factorize(df_hourly['weather_condition'])[0]\n",
    "    df_hourly.dropna(inplace=True)\n",
    "    return df_hourly\n",
    "\n",
    "\n",
    "\n",
    "def predict(df_hourly):\n",
    "    # X = df_hourly.drop(['available_bikes', 'weather_condition', 'station_id', 'bike_stands','available_bike_stands'], axis=1)\n",
    "    X = df_hourly[['day_of_the_week', 'hour', 'weather_condition_encoded', 'is_weekend', 'temperature','humidity','wind_speed']]\n",
    "    # X.to_csv(\"cs123.csv\")\n",
    "    y = df_hourly['available_bikes']\n",
    "\n",
    "    \n",
    "    # Temporal train-test split\n",
    "    # y_train, y_test, X_train, X_test = temporal_train_test_split(y, X, test_size=0.2)\n",
    "    # y_train, y_test, X_train, X_test = train_test_split(y, X, test_size=0.2, random_state=42)\n",
    "    y_train, y_test, X_train, X_test = temporal_train_test_split(y, X, test_size=0.2)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Initialize and fit the KNN Regressor\n",
    "    knn_regressor = KNeighborsRegressor(n_neighbors=5)\n",
    "    knn_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "    \n",
    "    # Predict on the test set\n",
    "    # y_pred = knn_regressor.predict(X_test_scaled)\n",
    "    return knn_regressor, y_test, y_pred\n",
    "\n",
    "\n",
    "def evaluate(y_test, y_pred, verbose=True):\n",
    "    # Calculate and display performance metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    # Plot the true vs predicted values\n",
    "    if verbose:\n",
    "        print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "        print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "        print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "        print(f\"R-squared (R²): {r2}\")\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(y_test.index, y_test, label='Actual', marker='o')\n",
    "        plt.plot(y_test.index, y_pred, label='Predicted', marker='x')\n",
    "        plt.title('Actual vs Predicted Available Bikes - Test Set')\n",
    "        plt.xlabel('Timestamp')\n",
    "        plt.ylabel('Available Bikes')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "def calculate_acc(acceptable_error):\n",
    "    \n",
    "    # Calculate the absolute errors\n",
    "    absolute_errors = np.abs(y_pred - y_test)\n",
    "    \n",
    "    # Determine the percentage of predictions within the acceptable error margin\n",
    "    accurate_predictions = (absolute_errors <= acceptable_error).mean()\n",
    "    \n",
    "    # Convert to percentage\n",
    "    accuracy_percentage = accurate_predictions * 100\n",
    "    return accuracy_percentage\n",
    "    # print(f\"Model 'accuracy' within ±{acceptable_error} bikes: {accuracy_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "599ad13a-a07a-46db-ac32-0cf152a6e8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      station_id  bike_stands    last_update  available_bikes  \\\n",
      "0              4           20  1708595528000               20   \n",
      "1              4           20  1708596133000               20   \n",
      "2              4           20  1708596738000               20   \n",
      "3              4           20  1708597344000               20   \n",
      "4              4           20  1708597949000               20   \n",
      "...          ...          ...            ...              ...   \n",
      "7812           4           20  1712613044000                4   \n",
      "7813           4           20  1712613649000                4   \n",
      "7814           4           20  1712613923000                4   \n",
      "7815           4           20  1712614255000                4   \n",
      "7816           4           20  1712614860000                4   \n",
      "\n",
      "      available_bike_stands  temperature  humidity weather_condition  \\\n",
      "0                         0       278.69        85            Clouds   \n",
      "1                         0       278.79        85            Clouds   \n",
      "2                         0       278.79        84            Clouds   \n",
      "3                         0       278.79        84            Clouds   \n",
      "4                         0       278.75        85            Clouds   \n",
      "...                     ...          ...       ...               ...   \n",
      "7812                     16       279.33        93           Drizzle   \n",
      "7813                     16       279.30        93           Drizzle   \n",
      "7814                     16       279.30        93              Rain   \n",
      "7815                     16       279.30        93           Drizzle   \n",
      "7816                     16       279.18        94           Drizzle   \n",
      "\n",
      "      wind_speed  \n",
      "0           6.69  \n",
      "1           6.69  \n",
      "2           6.69  \n",
      "3           6.69  \n",
      "4           7.72  \n",
      "...          ...  \n",
      "7812        8.75  \n",
      "7813        8.75  \n",
      "7814        8.75  \n",
      "7815        8.75  \n",
      "7816        8.75  \n",
      "\n",
      "[7817 rows x 9 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [447, 446]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[174], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m model, y_test, y_pred \u001b[38;5;241m=\u001b[39m predict(df_hourly) \n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Step 5: Evaluate the model\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m evaluate(y_test, y_pred, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m acc \u001b[38;5;241m=\u001b[39m calculate_acc(acceptable_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m accuracies[i] \u001b[38;5;241m=\u001b[39m acc\n",
      "Cell \u001b[1;32mIn[173], line 86\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(y_test, y_pred, verbose)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(y_test, y_pred, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# Calculate and display performance metrics\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m     mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_test, y_pred)\n\u001b[0;32m     87\u001b[0m     mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred)\n\u001b[0;32m     88\u001b[0m     rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mse)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dublin-bikes-app\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dublin-bikes-app\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:207\u001b[0m, in \u001b[0;36mmean_absolute_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    144\u001b[0m     {\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    153\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m ):\n\u001b[0;32m    155\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_absolute_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    0.85...\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 207\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    208\u001b[0m         y_true, y_pred, multioutput\n\u001b[0;32m    209\u001b[0m     )\n\u001b[0;32m    210\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    211\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(np\u001b[38;5;241m.\u001b[39mabs(y_pred \u001b[38;5;241m-\u001b[39m y_true), weights\u001b[38;5;241m=\u001b[39msample_weight, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dublin-bikes-app\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:102\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     69\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m        correct keyword.\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[0;32m    103\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    104\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dublin-bikes-app\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [447, 446]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage of the functions:\n",
    "\n",
    "# Step 1: Get data\n",
    "accuracies = {}\n",
    "for i in range(4,5):\n",
    "    df = get_data(station_id=i)\n",
    "    \n",
    "    # Step 2: Clean data\n",
    "    if not df.empty:\n",
    "        \n",
    "        df_hourly = clean_data(df)\n",
    "    \n",
    "        # Step 4: Model and predict\n",
    "        model, y_test, y_pred = predict(df_hourly) \n",
    "        \n",
    "        # Step 5: Evaluate the model\n",
    "        evaluate(y_test, y_pred, True)\n",
    "        acc = calculate_acc(acceptable_error = 1)\n",
    "   \n",
    "        accuracies[i] = acc\n",
    "\n",
    "\n",
    "\n",
    "# Assuming df_hourly is your DataFrame ready for feature engineering\n",
    "\n",
    "# # Step 1: Extract day of the week (Monday=0, Sunday=6)\n",
    "# df_hourly['day_of_week'] = df_hourly.index.dayofweek\n",
    "\n",
    "# # Step 2: Determine if it's a weekend\n",
    "# df_hourly['is_weekend'] = df_hourly['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "# # Step 3: Determine if it's rush hour\n",
    "# # Rush hours are considered to be 7-9 and 16-19 from Monday to Friday\n",
    "# def is_rush_hour(row):\n",
    "#     if row['day_of_week'] >= 5:  # It's a weekend\n",
    "#         return 0\n",
    "#     if 7 <= row.name.hour <= 9 or 16 <= row.name.hour <= 19:\n",
    "#         return 1\n",
    "#     return 0\n",
    "\n",
    "# df_hourly['is_rush_hour'] = df_hourly.apply(is_rush_hour, axis=1)\n",
    "\n",
    "# # Now you can drop the 'day_of_week' column if it's no longer needed for modeling\n",
    "# df_hourly.drop(['day_of_week'], axis=1, inplace=True)\n",
    "\n",
    "# # Continue with your modeling as before\n",
    "\n",
    "# Extracting station IDs and their accuracies\n",
    "stations = list(accuracies.keys())\n",
    "accuracy_values = list(accuracies.values())\n",
    "print(np.mean(accuracy_values))\n",
    "# Plotting\n",
    "plt.figure(figsize=(20, 6))  # Adjust the figure size as needed\n",
    "plt.bar(stations, accuracy_values, color='skyblue')\n",
    "\n",
    "plt.xlabel('Station ID')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Prediction Accuracy by Station')\n",
    "plt.xticks(stations, rotation='vertical')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f098ca9-51b7-48ce-98e3-54a9299e9ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311 dublin bikes app",
   "language": "python",
   "name": "dublin-bikes-app"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
